{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import all necessary libraries for the web search agent including os, json, pathlib, requests, serpapi, and LangGraph components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os  # For environment variable access\n",
    "import json  # For handling JSON data\n",
    "import pathlib  # For file and directory operations\n",
    "import requests  # For making HTTP requests\n",
    "from serpapi import GoogleSearch  # For interacting with SerpAPI\n",
    "\n",
    "# Import LangGraph components\n",
    "from langgraph.graph import StateGraph, END  # For building and managing LangGraph pipelines\n",
    "from langchain_core.runnables import RunnableLambda  # For creating runnable nodes in LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Environment Variables\n",
    "Set up the SerpAPI key as an environment variable and verify it's available. Create necessary directories for storing search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the SerpAPI key as an environment variable\n",
    "serp_api_key = \"your_serpapi_key_here\"  # Replace with your actual SerpAPI key\n",
    "os.environ[\"SERP_API_KEY\"] = serp_api_key\n",
    "\n",
    "# Verify that the SerpAPI key is available\n",
    "if not os.getenv(\"SERP_API_KEY\"):\n",
    "    raise ValueError(\"SERP_API_KEY not found in environment variables\")\n",
    "\n",
    "# Create necessary directories for storing search results\n",
    "content_dir = pathlib.Path(\"WebAgent/content\")\n",
    "content_dir.mkdir(parents=True, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# Confirm directory creation\n",
    "assert content_dir.exists(), \"Failed to create the content directory\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement NvidiaWebSearchAgent\n",
    "Create the NvidiaWebSearchAgent class that will handle different types of web searches related to NVIDIA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the NvidiaWebSearchAgent class\n",
    "class NvidiaWebSearchAgent:\n",
    "    \"\"\"\n",
    "    Agent for retrieving real-time web information about NVIDIA using SerpAPI.\n",
    "    It can search for general topics, latest news, financial info, and quarterly reports.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.api_key = os.getenv(\"SERP_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"SERP_API_KEY not found in environment variables\")\n",
    "        \n",
    "        # Directory for storing markdown content\n",
    "        self.content_dir = pathlib.Path(\"WebAgent/content\")\n",
    "        self.content_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Dictionary to store links from different searches\n",
    "        self.nvidia_links = {\n",
    "            \"general\": [],\n",
    "            \"news\": [],\n",
    "            \"financial\": [],\n",
    "            \"quarterly\": []\n",
    "        }\n",
    "    \n",
    "    def search(self, query: str, num_results: int = 5, location: str = \"United States\") -> dict:\n",
    "        \"\"\"\n",
    "        Perform a general search using SerpAPI.\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"location\": location,\n",
    "            \"api_key\": self.api_key,\n",
    "            \"hl\": \"en\",\n",
    "            \"num\": num_results,\n",
    "            \"gl\": \"us\"\n",
    "        }\n",
    "        search = GoogleSearch(params)\n",
    "        raw_results = search.get_dict()\n",
    "        processed_results = {\n",
    "            \"query\": query,\n",
    "            \"search_timestamp\": datetime.now().isoformat(),\n",
    "            \"organic_results\": self._extract_organic_results(raw_results, num_results),\n",
    "        }\n",
    "        if \"news_results\" in raw_results:\n",
    "            processed_results[\"news_results\"] = self._extract_news_results(raw_results, num_results)\n",
    "        if \"organic_results\" in processed_results:\n",
    "            self.nvidia_links[\"general\"] = [result[\"link\"] for result in processed_results[\"organic_results\"]]\n",
    "        return processed_results\n",
    "    \n",
    "    def search_news(self, query: str = \"nvidia\", num_results: int = 5) -> dict:\n",
    "        \"\"\"\n",
    "        Perform a news-specific search using SerpAPI.\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            \"q\": f\"{query} news\",\n",
    "            \"tbm\": \"nws\",\n",
    "            \"api_key\": self.api_key,\n",
    "            \"hl\": \"en\",\n",
    "            \"num\": num_results\n",
    "        }\n",
    "        search = GoogleSearch(params)\n",
    "        raw_results = search.get_dict()\n",
    "        results = {\n",
    "            \"query\": f\"{query} news\",\n",
    "            \"search_timestamp\": datetime.now().isoformat(),\n",
    "            \"news_results\": self._extract_news_results(raw_results, num_results)\n",
    "        }\n",
    "        if \"news_results\" in results:\n",
    "            self.nvidia_links[\"news\"] = [result[\"link\"] for result in results[\"news_results\"]]\n",
    "        return results\n",
    "    \n",
    "    def search_financial_info(self, specific_topic: Optional[str] = None) -> dict:\n",
    "        \"\"\"\n",
    "        Perform a financial information search using SerpAPI.\n",
    "        \"\"\"\n",
    "        query = \"nvidia financial\" if not specific_topic else f\"nvidia {specific_topic} financial\"\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"api_key\": self.api_key,\n",
    "            \"hl\": \"en\",\n",
    "            \"gl\": \"us\"\n",
    "        }\n",
    "        search = GoogleSearch(params)\n",
    "        raw_results = search.get_dict()\n",
    "        results = {\n",
    "            \"query\": query,\n",
    "            \"search_timestamp\": datetime.now().isoformat(),\n",
    "            \"financial_results\": self._extract_organic_results(raw_results, 5)\n",
    "        }\n",
    "        if \"financial_results\" in results:\n",
    "            self.nvidia_links[\"financial\"] = [result[\"link\"] for result in results[\"financial_results\"]]\n",
    "        return results\n",
    "    \n",
    "    def search_quarterly_report_info(self, year: Optional[int] = None, quarter: Optional[int] = None) -> dict:\n",
    "        \"\"\"\n",
    "        Searches for NVIDIA quarterly report information.\n",
    "        \"\"\"\n",
    "        query = \"nvidia quarterly report\"\n",
    "        if year:\n",
    "            query += f\" {year}\"\n",
    "        if quarter and 1 <= quarter <= 4:\n",
    "            query += f\" Q{quarter}\"\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"api_key\": self.api_key,\n",
    "            \"hl\": \"en\",\n",
    "            \"gl\": \"us\"\n",
    "        }\n",
    "        search = GoogleSearch(params)\n",
    "        raw_results = search.get_dict()\n",
    "        results = {\n",
    "            \"query\": query,\n",
    "            \"search_timestamp\": datetime.now().isoformat(),\n",
    "            \"year\": year,\n",
    "            \"quarter\": quarter,\n",
    "            \"results\": self._extract_organic_results(raw_results, 5)\n",
    "        }\n",
    "        if \"results\" in results:\n",
    "            self.nvidia_links[\"quarterly\"] = [result[\"link\"] for result in results[\"results\"]]\n",
    "        return results\n",
    "    \n",
    "    def _extract_organic_results(self, raw_results: dict, limit: int) -> List[dict]:\n",
    "        \"\"\"\n",
    "        Extract organic search results from raw SerpAPI response.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        if \"organic_results\" in raw_results and raw_results[\"organic_results\"]:\n",
    "            for item in raw_results[\"organic_results\"][:limit]:\n",
    "                result = {\n",
    "                    \"title\": item.get(\"title\", \"\"),\n",
    "                    \"link\": item.get(\"link\", \"\"),\n",
    "                    \"snippet\": item.get(\"snippet\", \"\")\n",
    "                }\n",
    "                if \"displayed_link\" in item:\n",
    "                    result[\"source\"] = item[\"displayed_link\"]\n",
    "                results.append(result)\n",
    "        return results\n",
    "    \n",
    "    def _extract_news_results(self, raw_results: dict, limit: int) -> List[dict]:\n",
    "        \"\"\"\n",
    "        Extract news search results from raw SerpAPI response.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        news_results = raw_results.get(\"news_results\", [])\n",
    "        if not news_results and \"organic_results\" in raw_results:\n",
    "            return self._extract_organic_results(raw_results, limit)\n",
    "        for item in news_results[:limit]:\n",
    "            result = {\n",
    "                \"title\": item.get(\"title\", \"\"),\n",
    "                \"link\": item.get(\"link\", \"\"),\n",
    "                \"snippet\": item.get(\"snippet\", \"\")\n",
    "            }\n",
    "            if \"source\" in item:\n",
    "                result[\"source\"] = item[\"source\"]\n",
    "            if \"date\" in item:\n",
    "                result[\"date\"] = item[\"date\"]\n",
    "            results.append(result)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Search Functions\n",
    "Implement the various search methods: general search, news search, financial information search, and quarterly report search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search functions for the NvidiaWebSearchAgent class\n",
    "\n",
    "def search(self, query: str, num_results: int = 5, location: str = \"United States\") -> dict:\n",
    "    \"\"\"\n",
    "    Perform a general search using SerpAPI.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"location\": location,\n",
    "        \"api_key\": self.api_key,\n",
    "        \"hl\": \"en\",\n",
    "        \"num\": num_results,\n",
    "        \"gl\": \"us\"\n",
    "    }\n",
    "    search = GoogleSearch(params)\n",
    "    raw_results = search.get_dict()\n",
    "    processed_results = {\n",
    "        \"query\": query,\n",
    "        \"search_timestamp\": datetime.now().isoformat(),\n",
    "        \"organic_results\": self._extract_organic_results(raw_results, num_results),\n",
    "    }\n",
    "    if \"news_results\" in raw_results:\n",
    "        processed_results[\"news_results\"] = self._extract_news_results(raw_results, num_results)\n",
    "    if \"organic_results\" in processed_results:\n",
    "        self.nvidia_links[\"general\"] = [result[\"link\"] for result in processed_results[\"organic_results\"]]\n",
    "    return processed_results\n",
    "\n",
    "def search_news(self, query: str = \"nvidia\", num_results: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Perform a news-specific search using SerpAPI.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"q\": f\"{query} news\",\n",
    "        \"tbm\": \"nws\",\n",
    "        \"api_key\": self.api_key,\n",
    "        \"hl\": \"en\",\n",
    "        \"num\": num_results\n",
    "    }\n",
    "    search = GoogleSearch(params)\n",
    "    raw_results = search.get_dict()\n",
    "    results = {\n",
    "        \"query\": f\"{query} news\",\n",
    "        \"search_timestamp\": datetime.now().isoformat(),\n",
    "        \"news_results\": self._extract_news_results(raw_results, num_results)\n",
    "    }\n",
    "    if \"news_results\" in results:\n",
    "        self.nvidia_links[\"news\"] = [result[\"link\"] for result in results[\"news_results\"]]\n",
    "    return results\n",
    "\n",
    "def search_financial_info(self, specific_topic: Optional[str] = None) -> dict:\n",
    "    \"\"\"\n",
    "    Perform a financial information search using SerpAPI.\n",
    "    \"\"\"\n",
    "    query = \"nvidia financial\" if not specific_topic else f\"nvidia {specific_topic} financial\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"api_key\": self.api_key,\n",
    "        \"hl\": \"en\",\n",
    "        \"gl\": \"us\"\n",
    "    }\n",
    "    search = GoogleSearch(params)\n",
    "    raw_results = search.get_dict()\n",
    "    results = {\n",
    "        \"query\": query,\n",
    "        \"search_timestamp\": datetime.now().isoformat(),\n",
    "        \"financial_results\": self._extract_organic_results(raw_results, 5)\n",
    "    }\n",
    "    if \"financial_results\" in results:\n",
    "        self.nvidia_links[\"financial\"] = [result[\"link\"] for result in results[\"financial_results\"]]\n",
    "    return results\n",
    "\n",
    "def search_quarterly_report_info(self, year: Optional[int] = None, quarter: Optional[int] = None) -> dict:\n",
    "    \"\"\"\n",
    "    Searches for NVIDIA quarterly report information.\n",
    "    \"\"\"\n",
    "    query = \"nvidia quarterly report\"\n",
    "    if year:\n",
    "        query += f\" {year}\"\n",
    "    if quarter and 1 <= quarter <= 4:\n",
    "        query += f\" Q{quarter}\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"api_key\": self.api_key,\n",
    "        \"hl\": \"en\",\n",
    "        \"gl\": \"us\"\n",
    "    }\n",
    "    search = GoogleSearch(params)\n",
    "    raw_results = search.get_dict()\n",
    "    results = {\n",
    "        \"query\": query,\n",
    "        \"search_timestamp\": datetime.now().isoformat(),\n",
    "        \"year\": year,\n",
    "        \"quarter\": quarter,\n",
    "        \"results\": self._extract_organic_results(raw_results, 5)\n",
    "    }\n",
    "    if \"results\" in results:\n",
    "        self.nvidia_links[\"quarterly\"] = [result[\"link\"] for result in results[\"results\"]]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create LangGraph State and Agent\n",
    "Define the WebSearchState TypedDict and implement the nvidia_web_search_agent function that will be used in the LangGraph pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional, Dict, Any\n",
    "\n",
    "# Define the WebSearchState TypedDict\n",
    "class WebSearchState(TypedDict, total=False):\n",
    "    year: int  # Year for the quarterly report\n",
    "    quarter: int  # Quarter for the quarterly report\n",
    "    organized_result: Dict[str, Any]  # Structured result of the search\n",
    "\n",
    "# Define the nvidia_web_search_agent function\n",
    "def nvidia_web_search_agent(state: WebSearchState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    LangGraph agent function that uses NvidiaWebSearchAgent to query quarterly report info.\n",
    "    It organizes the result into a structured dictionary.\n",
    "    \"\"\"\n",
    "    year = state.get(\"year\", None)\n",
    "    quarter = state.get(\"quarter\", None)\n",
    "    \n",
    "    try:\n",
    "        # Instantiate the NvidiaWebSearchAgent\n",
    "        agent = NvidiaWebSearchAgent()\n",
    "        \n",
    "        # Perform the search for quarterly report information\n",
    "        search_results = agent.search_quarterly_report_info(year=year, quarter=quarter)\n",
    "        \n",
    "        # Organize the search results\n",
    "        organized = {\n",
    "            \"query\": search_results.get(\"query\", \"\"),\n",
    "            \"search_timestamp\": search_results.get(\"search_timestamp\", \"\"),\n",
    "            \"year\": search_results.get(\"year\", year),\n",
    "            \"quarter\": search_results.get(\"quarter\", quarter),\n",
    "            \"results\": search_results.get(\"results\", [])\n",
    "        }\n",
    "        return {\"organized_result\": organized}\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions and return an error message\n",
    "        return {\"organized_result\": f\"Error: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the LangGraph Pipeline\n",
    "Create and compile the LangGraph pipeline with appropriate nodes and edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LangGraph pipeline\n",
    "def build_graph():\n",
    "    \"\"\"\n",
    "    Build and compile the LangGraph pipeline with a single node that executes the Nvidia web search.\n",
    "    \"\"\"\n",
    "    # Initialize the StateGraph with the WebSearchState type\n",
    "    builder = StateGraph(WebSearchState)\n",
    "    \n",
    "    # Add a node for the NvidiaWebSearchAgent function\n",
    "    builder.add_node(\"NvidiaWebSearchAgent\", RunnableLambda(nvidia_web_search_agent))\n",
    "    \n",
    "    # Set the entry point of the graph to the NvidiaWebSearchAgent node\n",
    "    builder.set_entry_point(\"NvidiaWebSearchAgent\")\n",
    "    \n",
    "    # Add an edge from the NvidiaWebSearchAgent node to the END node\n",
    "    builder.add_edge(\"NvidiaWebSearchAgent\", END)\n",
    "    \n",
    "    # Compile and return the graph\n",
    "    return builder.compile()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
